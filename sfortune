#!/usr/bin/env python3

from html.parser import HTMLParser
from urllib import request as URL
import argparse
import sys
import signal
import traceback

def signal_handler(signal, frame):
    sys.exit(0)
signal.signal(signal.SIGINT, signal_handler)

class FactParser(HTMLParser):
	def __init__(self):
		HTMLParser.__init__(self)
		self.fact = ""
		self.factActive = False

	def handle_starttag(self, tag, attrs):
		if tag == 'p' and ("class", "fact") in attrs:
			self.factActive = True

	def handle_data(self, data):
		if self.factActive:
			self.fact = self.fact + data

	def handle_charref(self, name):
		if self.factActive:
			self.fact = self.fact + "&#" + name + ";"

	def handle_entityref(self, name):
		None

	def handle_endtag(self, tag):
		if self.factActive:
			self.factActive = False

	def getFact(self):
		return self.unescape(self.fact).strip()

class NextLinkParser(HTMLParser):
	def __init__(self):
		HTMLParser.__init__(self)
		self.nextLink = ""
		self.nextLinkFound = False
		self.linkText = ""
		self.linkActive = False

	def handle_starttag(self, tag, attrs):
		if tag == 'a' and not self.nextLinkFound:
			self.linkActive = True

			for attr in attrs:
				if attr[0] == "href":
					self.nextLink = attr[1]
					break

			if not self.nextLinkFound:
				self.linkText = ""

	def handle_data(self, data):
		if self.linkActive:
			self.linkText = self.linkText + data

	def handle_endtag(self, tag):
		if self.linkActive == True:
			self.linkActive = False
			if self.linkText.find("Next Fact") != -1:
				self.nextLinkFound = True
			else:
				self.linkText = ""

	def getLink(self):
		if not self.nextLinkFound:
			return None
		else:
			return self.nextLink


def getSchneierFactPage(number = None):
	factUrl = "http://www.schneierfacts.com/"
	if isinstance( number, ( int ) ):
		assert(number > 0)
		factUrl = factUrl + 'fact/' + str(number)
	urlHandle = URL.urlopen(factUrl, timeout=5)
	return str(urlHandle.read(), "utf-8")

def getFactFromPage(factHtmlPage):
	pageParser = FactParser()
	pageParser.feed(factHtmlPage)
	pageParser.close()
	fact = pageParser.getFact()
	return fact

def getNextLinkFromPage(factHtmlPage):
	pageParser = NextLinkParser()
	pageParser.feed(factHtmlPage)
	pageParser.close()
	link = pageParser.getLink()
	return link

def handleFact(number = None):
	factHtmlPage = ""
	try:
		factHtmlPage = getSchneierFactPage(number)
	except KeyboardInterrupt:
		None
	except SystemExit:
		None
	except:
		print('ERROR: Downloading random Schneier fact failed. Exiting.')
		traceback.print_exc()
		sys.exit(1)

	fact = getFactFromPage(factHtmlPage)
	nextLink = getNextLinkFromPage(factHtmlPage)

	return (fact, nextLink)

if __name__ == "__main__":
	# parse arguments
	parser = argparse.ArgumentParser(description='Load ironic facts about Bruce Schneier from http://www.schneierfacts.com')
	parser.add_argument('factnumber', metavar='N', type=int, nargs='?',
						help='number of the fact to load')
	parser.add_argument('--all', action="store_true", default=False, help="Fetch all Facts from http://www.schneierfacts.com")
	args = parser.parse_args()

	if args.factnumber != None and args.all:
		print("ERROR: Do you want all or only a single fact?")
		sys.exit(1)

	if not args.all:
		(fact, nextLink) = handleFact(args.factnumber)
		print(fact)
	else:
		factnumber = 1
		while True:
			(fact, nextLink) = handleFact(factnumber)
			if fact != None:
				print(fact)
			else:
				break
			if nextLink == None:
				break
			else:
				factnumber = int(nextLink.split("/")[-1])
